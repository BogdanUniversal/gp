{
    "name": "Multiplication",
    "attributes": {
        "type": "primitive",
        "arity": 2,
        "doc": "(function) def mul(arg0: float, arg1: float) -> float\nSame as a * b.",
        "returnType": "float"
    },
    "children": [
        {
            "name": "IN3",
            "attributes": {
                "type": "variable"
            }
        },
        {
            "name": "Substraction",
            "attributes": {
                "type": "primitive",
                "arity": 2,
                "doc": "(function) def sub(arg0: float, arg1: float) -> float\nSame as a - b.",
                "returnType": "float"
            },
            "children": [
                {
                    "name": "Protected Division",
                    "attributes": {
                        "type": "primitive",
                        "arity": 2,
                        "doc": "(function) def protected_div(arg0: float, arg1: float) -> float\nSafely performs division between two numbers.\n    Divides `arg0` by `arg1` and returns the result. If a division by zero occurs,\n    returns 1 instead of raising an exception.\n    Args:\n        arg0 (Primitive): The numerator.\n        arg1 (Primitive): The denominator.\n    Returns:\n        Primitive: The result of the division, or 1 if `arg1` is zero.",
                        "returnType": "float"
                    },
                    "children": [
                        {
                            "name": "Random Wald (1 Mean)",
                            "attributes": {
                                "type": "ephemeral",
                                "arity": 0,
                                "returnType": "float",
                                "doc": "\n        wald(mean, scale, size=None)\n\n        Draw samples from a Wald, or inverse Gaussian, distribution.\n\n        As the scale approaches infinity, the distribution becomes more like a\n        Gaussian. Some references claim that the Wald is an inverse Gaussian\n        with mean equal to 1, but this is by no means universal.\n\n        The inverse Gaussian distribution was first studied in relationship to\n        Brownian motion. In 1956 M.C.K. Tweedie used the name inverse Gaussian\n        because there is an inverse relationship between the time to cover a\n        unit distance and distance covered in unit time.\n\n        .. note::\n            New code should use the `~numpy.random.Generator.wald`\n            method of a `~numpy.random.Generator` instance instead;\n            please see the :ref:`random-quick-start`.\n\n        Parameters\n        ----------\n        mean : float or array_like of floats\n            Distribution mean, must be > 0.\n        scale : float or array_like of floats\n            Scale parameter, must be > 0.\n        size : int or tuple of ints, optional\n            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n            a single value is returned if ``mean`` and ``scale`` are both scalars.\n            Otherwise, ``np.broadcast(mean, scale).size`` samples are drawn.\n\n        Returns\n        -------\n        out : ndarray or scalar\n            Drawn samples from the parameterized Wald distribution.\n\n        See Also\n        --------\n        random.Generator.wald: which should be used for new code.\n\n        Notes\n        -----\n        The probability density function for the Wald distribution is\n\n        .. math:: P(x;mean,scale) = \\sqrt{\\frac{scale}{2\\pi x^3}}e^\n                                    \\frac{-scale(x-mean)^2}{2\\cdotp mean^2x}\n\n        As noted above the inverse Gaussian distribution first arise\n        from attempts to model Brownian motion. It is also a\n        competitor to the Weibull for use in reliability modeling and\n        modeling stock returns and interest rate processes.\n\n        References\n        ----------\n        .. [1] Brighton Webs Ltd., Wald Distribution,\n               https://web.archive.org/web/20090423014010/http://www.brighton-webs.co.uk:80/distributions/wald.asp\n        .. [2] Chhikara, Raj S., and Folks, J. Leroy, \"The Inverse Gaussian\n               Distribution: Theory : Methodology, and Applications\", CRC Press,\n               1988.\n        .. [3] Wikipedia, \"Inverse Gaussian distribution\"\n               https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution\n\n        Examples\n        --------\n        Draw values from the distribution and plot the histogram:\n\n        >>> import matplotlib.pyplot as plt\n        >>> h = plt.hist(np.random.wald(3, 2, 100000), bins=200, density=True)\n        >>> plt.show()\n\n        ",
                                "value": 4.999172908885714
                            }
                        },
                        {
                            "name": "Random Pareto (1 Shape)",
                            "attributes": {
                                "type": "ephemeral",
                                "arity": 0,
                                "returnType": "float",
                                "doc": "\n        pareto(a, size=None)\n\n        Draw samples from a Pareto II or Lomax distribution with\n        specified shape.\n\n        The Lomax or Pareto II distribution is a shifted Pareto\n        distribution. The classical Pareto distribution can be\n        obtained from the Lomax distribution by adding 1 and\n        multiplying by the scale parameter ``m`` (see Notes).  The\n        smallest value of the Lomax distribution is zero while for the\n        classical Pareto distribution it is ``mu``, where the standard\n        Pareto distribution has location ``mu = 1``.  Lomax can also\n        be considered as a simplified version of the Generalized\n        Pareto distribution (available in SciPy), with the scale set\n        to one and the location set to zero.\n\n        The Pareto distribution must be greater than zero, and is\n        unbounded above.  It is also known as the \"80-20 rule\".  In\n        this distribution, 80 percent of the weights are in the lowest\n        20 percent of the range, while the other 20 percent fill the\n        remaining 80 percent of the range.\n\n        .. note::\n            New code should use the `~numpy.random.Generator.pareto`\n            method of a `~numpy.random.Generator` instance instead;\n            please see the :ref:`random-quick-start`.\n\n        Parameters\n        ----------\n        a : float or array_like of floats\n            Shape of the distribution. Must be positive.\n        size : int or tuple of ints, optional\n            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n            a single value is returned if ``a`` is a scalar.  Otherwise,\n            ``np.array(a).size`` samples are drawn.\n\n        Returns\n        -------\n        out : ndarray or scalar\n            Drawn samples from the parameterized Pareto distribution.\n\n        See Also\n        --------\n        scipy.stats.lomax : probability density function, distribution or\n            cumulative density function, etc.\n        scipy.stats.genpareto : probability density function, distribution or\n            cumulative density function, etc.\n        random.Generator.pareto: which should be used for new code.\n\n        Notes\n        -----\n        The probability density for the Pareto distribution is\n\n        .. math:: p(x) = \\frac{am^a}{x^{a+1}}\n\n        where :math:`a` is the shape and :math:`m` the scale.\n\n        The Pareto distribution, named after the Italian economist\n        Vilfredo Pareto, is a power law probability distribution\n        useful in many real world problems.  Outside the field of\n        economics it is generally referred to as the Bradford\n        distribution. Pareto developed the distribution to describe\n        the distribution of wealth in an economy.  It has also found\n        use in insurance, web page access statistics, oil field sizes,\n        and many other problems, including the download frequency for\n        projects in Sourceforge [1]_.  It is one of the so-called\n        \"fat-tailed\" distributions.\n\n        References\n        ----------\n        .. [1] Francis Hunt and Paul Johnson, On the Pareto Distribution of\n               Sourceforge projects.\n        .. [2] Pareto, V. (1896). Course of Political Economy. Lausanne.\n        .. [3] Reiss, R.D., Thomas, M.(2001), Statistical Analysis of Extreme\n               Values, Birkhauser Verlag, Basel, pp 23-30.\n        .. [4] Wikipedia, \"Pareto distribution\",\n               https://en.wikipedia.org/wiki/Pareto_distribution\n\n        Examples\n        --------\n        Draw samples from the distribution:\n\n        >>> a, m = 3., 2.  # shape and mode\n        >>> s = (np.random.pareto(a, 1000) + 1) * m\n\n        Display the histogram of the samples, along with the probability\n        density function:\n\n        >>> import matplotlib.pyplot as plt\n        >>> count, bins, _ = plt.hist(s, 100, density=True)\n        >>> fit = a*m**a / bins**(a+1)\n        >>> plt.plot(bins, max(count)*fit/max(fit), linewidth=2, color='r')\n        >>> plt.show()\n\n        ",
                                "value": 0.9107998837834475
                            }
                        }
                    ]
                },
                {
                    "name": "Random Wald (1 Mean)",
                    "attributes": {
                        "type": "ephemeral",
                        "arity": 0,
                        "returnType": "float",
                        "doc": "\n        wald(mean, scale, size=None)\n\n        Draw samples from a Wald, or inverse Gaussian, distribution.\n\n        As the scale approaches infinity, the distribution becomes more like a\n        Gaussian. Some references claim that the Wald is an inverse Gaussian\n        with mean equal to 1, but this is by no means universal.\n\n        The inverse Gaussian distribution was first studied in relationship to\n        Brownian motion. In 1956 M.C.K. Tweedie used the name inverse Gaussian\n        because there is an inverse relationship between the time to cover a\n        unit distance and distance covered in unit time.\n\n        .. note::\n            New code should use the `~numpy.random.Generator.wald`\n            method of a `~numpy.random.Generator` instance instead;\n            please see the :ref:`random-quick-start`.\n\n        Parameters\n        ----------\n        mean : float or array_like of floats\n            Distribution mean, must be > 0.\n        scale : float or array_like of floats\n            Scale parameter, must be > 0.\n        size : int or tuple of ints, optional\n            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n            a single value is returned if ``mean`` and ``scale`` are both scalars.\n            Otherwise, ``np.broadcast(mean, scale).size`` samples are drawn.\n\n        Returns\n        -------\n        out : ndarray or scalar\n            Drawn samples from the parameterized Wald distribution.\n\n        See Also\n        --------\n        random.Generator.wald: which should be used for new code.\n\n        Notes\n        -----\n        The probability density function for the Wald distribution is\n\n        .. math:: P(x;mean,scale) = \\sqrt{\\frac{scale}{2\\pi x^3}}e^\n                                    \\frac{-scale(x-mean)^2}{2\\cdotp mean^2x}\n\n        As noted above the inverse Gaussian distribution first arise\n        from attempts to model Brownian motion. It is also a\n        competitor to the Weibull for use in reliability modeling and\n        modeling stock returns and interest rate processes.\n\n        References\n        ----------\n        .. [1] Brighton Webs Ltd., Wald Distribution,\n               https://web.archive.org/web/20090423014010/http://www.brighton-webs.co.uk:80/distributions/wald.asp\n        .. [2] Chhikara, Raj S., and Folks, J. Leroy, \"The Inverse Gaussian\n               Distribution: Theory : Methodology, and Applications\", CRC Press,\n               1988.\n        .. [3] Wikipedia, \"Inverse Gaussian distribution\"\n               https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution\n\n        Examples\n        --------\n        Draw values from the distribution and plot the histogram:\n\n        >>> import matplotlib.pyplot as plt\n        >>> h = plt.hist(np.random.wald(3, 2, 100000), bins=200, density=True)\n        >>> plt.show()\n\n        ",
                        "value": 1.5375043283555723
                    }
                }
            ]
        }
    ]
}